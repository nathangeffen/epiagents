<!DOCTYPE html>
<html lang="en">

    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="author" content="Nathan Geffen" >
        <meta name="description" content="Epidemiology: Macro and micro models for infectious disease epidemics">
        <meta name="keywords" content="Epidemiology,models,micro models,macro models,agent-based models,simulation,infectious disease">
        <title>Modelling infectious diseases</title>
        <link rel="stylesheet" href="epi.css?v=20230321">
    </head>

    <!--
         Epidemiological modelling demonstration: Macro and micro models for
         infectious disease epidemics.

         Copyright (C) 2023  Nathan Geffen
         This program is free software: you can redistribute it and/or modify
         it under the terms of the GNU Affero General Public License as
         published by the Free Software Foundation, either version 3 of the
         License, or (at your option) any later version.

         This program is distributed in the hope that it will be useful,
         but WITHOUT ANY WARRANTY; without even the implied warranty of
         MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
         GNU Affero General Public License for more details.

         You should have received a copy of the GNU Affero General Public License
         along with this program.  If not, see <https://www.gnu.org/licenses/>.

         The source code for this project is available here:
         https://github.com/nathangeffen/understandingepi

         DO NOT MOVE THIS NOTICE ABOUT THE <meta charset="utf-8"> line to avoid
         HTML validation error.
    -->

    <body>

        <h1>Modelling infectious diseases</h1>

        <p class="date-heading">
            Published: <time datetime="2023-03-25">25 March 2023</time>.
            Last updated: <time datetime="2023-03-25">25 March 2023</time>
        </p>

        <div id="toc-bar">
            <div id="toc-container">
                <div id="table-of-contents" class="toc">
                    <h5>Contents</h5>
                    <noscript>
                        You need Javascript enabled to see the table of contents.
                    </noscript>
                </div>

                <div id="table-of-asides" class="toc">
                    <h5>Asides</h5>
                    <noscript>
                        You need Javascript enabled to see the list of asides.
                    </noscript>
                </div>
            </div>
        </div>

        <h2>Cows and the origins of epidemiological modelling</h2>
        <p>
            In late 1865 cows began dying in large numbers in England. This
            cattle plague was probably caused by the Rinderpest virus. Beef had
            become a vital part of the economy and so there was concern at the
            highest level of government. A commission was set up to investigate
            the epidemic. In February 1866, <a href="https://en.wikipedia.org/wiki/Robert_Lowe">Robert Lowe</a>,
            a Member of Parliament on this commission, made a gloomy prediction:
        </p>
        <blockquote>
            If we do not get the disease under by the middle of April, prepare
            yourself for a calamity beyond all calculation. You have seen the
            thing in its infancy. Wait and you will see the averages, which have
            been thousands, grow to tens of thousands, for there is no reason
            why the same terrible law of increase which has prevailed hitherto
            should not prevail henceforth. (<a href="https://www.jstor.org/stable/25314501">Brownlee,
            BMJ, 14 Aug 1915, p. 251</a>)
        </blockquote>
        <p>
            William Farr was an epidemiologist who had in 1840 shown that the
            distribution of smallpox deaths were approximated by a normal curve.<span class="footnote">
            Actually the term "normal" wasn't part of statistical terminology
            until <a href="https://condor.depaul.edu/ntiourir/NormalOrigin.htm">
            several decades later</a>. Farr <a href="https://en.wikipedia.org/wiki/Farr%27s_laws">wrote</a>:
            "The rates vary with the density of the population, the numbers
            susceptible of attack, the mortality, and the accidental
            circumstances; so that to obtain the mean rates applicable to
            the whole population, or to any portion of the population,
            several epidemics should be investigated. It appears probable,
            however, that the smallpox increases at an accelerated and then
            a retarded rate; that it declines first at a slightly
            accelerated, and at a rapidly accelerated, and lastly at a
            retarded rate, until the disease attains the minimum intensity,
            and remains stationary." That's indeed a description of what we
            today call a normal curve.
            </span>
        </p>
        <p>
            In 1866, responding to the cattle epidemic, Farr wrote a <a href="https://www.jstor.org/stable/25314501">letter</a> to the <a href="https://en.wikipedia.org/wiki/The_Daily_News_(UK)">Daily News</a>,
            a newspaper started 20 years earlier by Charles Dickens. He
            explained why things were not quite as awful as Lowe thought. He
            presented the recorded number of new cases for every four weeks
            since the epidemic started:
        </p>
        <div class="epi-table">
            <table>
                <caption>
                    Cattle plague infections 1865-66 (<a href="https://www.jstor.org/stable/25314501">Brownlee, BMJ, 14 Aug 1915, p. 251</a>)
                </caption>
                <thead>
                    <tr>
                        <th>
                            Date
                        </th>
                        <th>
                            Total Cases
                        </th>
                        <th>
                            New cases
                        </th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>
                            7 October
                        </td>
                        <td>
                            11,300
                        </td>
                        <td>
                            -
                        </td>
                    </tr>
                    <tr>
                        <td>
                            4 November
                        </td>
                        <td>
                            20,897
                        </td>
                        <td>
                            9,597
                        </td>
                    </tr>
                    <tr>
                        <td>
                            2 December
                        </td>
                        <td>
                            39,714
                        </td>
                        <td>
                            18,817
                        </td>
                    </tr>
                    <tr>
                        <td>
                            30 December
                        </td>
                        <td>
                            73,549
                        </td>
                        <td>
                            33,835
                        </td>
                    </tr>
                    <tr>
                        <td>
                            27 January
                        </td>
                        <td>
                            120,740
                        </td>
                        <td>
                            47,191
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>
        <p>
            What Farr noticed is that although the number of new cases was
            rising alarmingly, the rate at which they were increasing was
            dropping rapidly: 96% increase from 4 November 1865 to 2 December,
            80% from 2 December to 30 December and only 39% from 30 December to
            27 January 1866. Farr used this to estimate new cases in the
            coming months. The following table gives Farr's predictions alongside
            the actual recorded cases. As Brownlee points out the epidemic ended
            about two weeks later than Farr predicted. But this is nevertheless
            an impressively close match.
        </p>

        <div class="epi-table">
            <table>
                <caption>
                    Farr explained his method: "To obtain the series, multiply the
                    first number (9,597) by 1.9607, the product by 1.7981, and the
                    second product by 1.3947. It will be observed that these rates
                    decrease ; the second is obtained from the first by multiplying
                    by .9171, and the third from the second by multiplying by .7757.
                    Again, .7757 is obtained by multiplying .9171 by .8458. The
                    progress is simplified by employing logarithms, and the series
                    is continued by taking log. .9597, which equals 3.9821355; and
                    the three orders of differences of the logarithms of the numbers
                    derived from direct observation." <br>
                    Cattle plague infections 1865-66 (<a href="https://www.jstor.org/stable/25314501">Brownlee, BMJ, 14 Aug 1915, p. 251</a>)
                </caption>
                <thead>
                    <tr>
                        <th>Date</th>
                        <th>Predicted</th>
                        <th>Recorded </th>
                        <th>Note</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>4 Nov</td>
                        <td>9,597</td>
                        <td>9,597</td>
                        <td></td>
                    </tr>
                    <tr>
                        <td>2 Dec</td>
                        <td>18,817</td>
                        <td>18,817</td>
                        <td></td>
                    </tr>
                    <tr>
                        <td>30 Dec</td>
                        <td>33,835</td>
                        <td>33,835</td>
                        <td></td>
                    </tr>
                    <tr>
                        <td>27 Jan</td>
                        <td>47,191</td>
                        <td>47,287</td>
                        <td>(updated)</td>
                    </tr>
                    <tr>
                        <td>24 Feb</td>
                        <td>43,182</td>
                        <td>57,004</td>
                        <td></td>
                    </tr>
                    <tr>
                        <td>24 Mar</td>
                        <td>21,927</td>
                        <td>27,958</td>
                        <td></td>
                    </tr>
                    <tr>
                        <td>21 Apr</td>
                        <td>5,226</td>
                        <td>15,856</td>
                        <td></td>
                    </tr>
                    <tr>
                        <td>19 May</td>
                        <td>494</td>
                        <td>14,734</td>
                        <td></td>
                    </tr>
                    <tr>
                        <td>16 Jun</td>
                        <td>16</td>
                        <td>5,000</td>
                        <td>(approx)</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <p>
            Farr explained the mechanism at work here. I've edited his words
            into more modern English: "All germs are reproduced in every
            individual they attack. If they lose part of the force of infection
            in every body through which they pass, the epidemic has a tendency
            to subside. Also, the individuals left are less susceptible of
            attack, either by constitution or by hygienic conditions, than those
            killed. This is as true of infections in animals as it is of
            epidemics attacking people." (Adapted from <a href="https://www.jstor.org/stable/25314501">Brownlee, BMJ, 14 Aug 1915, p. 251</a>)
        </p>
        <p>
            Farr's letter explained how this reasoning applied to epidemics in
            humans, including cholera, diphtheria, influenza, measles and
            smallpox.
            <span class="footnote">From this one shouldn't conclude that Farr thought that
                diseases should simply be allowed to run their course. He wrote:
                "When an epidemic disease of foreign origin enters a country it
                encounters difficulties of diffusion, and it is undoubtedly wise to
                throw obstacles in its way, so that it may pass through its phases
                within the narrowest possible circle."</span>
        </p>

        <p>
            At the time Farr's letter was not well received. But by the early
            20th century Farr's thinking inspired several papers that tackled
            the mathematics of epidemics and led to our current ways of
            modelling epidemics. <a href="https://en.wikipedia.org/wiki/Anderson_Gray_McKendrick">Anderson McKendrick</a> and
            <a href="https://en.wikipedia.org/wiki/Anderson_Gray_McKendrick">William Kermack</a> in
            1927 articulated, albeit in a <a href="https://royalsocietypublishing.org/doi/epdf/10.1098/rspa.1927.0118">very difficult paper</a>,
            what we now call the Susceptible-Infectious-Recovered, or SIR,
            model. A somewhat simpler <a href="https://projecteuclid.org/ebooks/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-Third-Berkeley-Symposium-on-Mathematical-Statistics-and/chapter/Deterministic-and-Stochastic-Epidemics-in-Closed-Populations/bsmsp/1200502553">exposition of the SIR model</a>
            is given by David Kendall in 1956.
        </p>

        <p>
            Farr's insight that epidemics roughly follow a normal curve was
            certainly useful. With the hindsight of over 100 years of
            epidemiological modelling, it may seem obvious. But as we shall see,
            with measles and Covid for example, matters are often not this
            simple. Also, even in the idealised SIR models we shall look at, the
            distributions are skewed to the right.
        </p>

        <p><i>This page has little asides that you may find useful.
            Click the big green buttons to open and read them.</i>
        </p>
        <a id="copyright-details"></a>
        <aside>
            <button type="button">How to use the resources on this webpage</button>
            <div>
                <p>
                    This webpage uses only open-source software.
                    The text on this page is available for republication under <a href="https://creativecommons.org/licenses/by-sa/4.0/">this
                    Creative Commons license</a>. The Javascript and CSS files
                    that I've written for it are available under the <a href="https://www.gnu.org/licenses/agpl-3.0.en.html">GNU
                    Affero General Public License</a>.
                    <a href="https://www.chartjs.org/docs/latest/">Chart.js</a>
                    is used to generate the charts (MIT license),
                    and <a href="https://github.com/giannotr/runge-kutta-js">Ruben
                    Giannotti</a> wrote the differential equation solver (also
                    MIT license).  The <a href="">MathJax</a> library generates
                    the equations (Apache license). My C++ code is available
                    under the
                    <a href="https://www.gnu.org/licenses/gpl-3.0.en.html">GNU
                      General Public License</a>.  The C++ code on this page is
                      formatted
                      using <a href="https://github.com/googlearchive/code-prettify">Google's
                      code-prettify</a> (Apache 2.0 license).
                </p>
                <p>
                    I chose the GNU licenses to encourage anyone who uses and
                    modifies my code to make it publicly available. This is the
                    best way to do scientific programming.
                </p>
                <p>
                    It's all on <a href="https://github.com/nathangeffen/understandingepi">Github</a>.
                    So download, adapt, and improve the code as you see fit, but
                    please stick to the terms of the licenses.
                </p>
            </div>
        </aside>

        <aside>
            <button type="button">Interesting reading on the history of plagues</button>
            <div>
                <p>Thucydides, the Greek historian <a href="https://www.gutenberg.org/cache/epub/7142/pg7142-images.html">wrote</a> about the plague that
                    hit Athens in 430BC:</p>
                <blockquote>
                    "[A] pestilence of such extent and mortality was nowhere
                    remembered. Neither were the physicians at first of any
                    service, ignorant as they were of the proper way to treat
                    it, but they died themselves the most thickly, as they
                    visited the sick most often; nor did any human art succeed
                    any better. Supplications in the temples, divinations, and
                    so forth were found equally futile, till the overwhelming
                    nature of the disaster at last put a stop to them
                    altogether."
                </blockquote>
                <p>
                    Thucydides's description of the plague is worth reading.
                    It's a few pages long at the beginning of Chapter VII in <a href="https://www.gutenberg.org/cache/epub/7142/pg7142-images.html">The
                    History of the Peloponnesian War</a>. His factual, detailed
                    description of the plague is remarkable. There is no resort
                    to the supernatural. One might call his account modern, but
                    for the fact that many modern accounts of epidemics are much
                    less accurate than Thucydides. Importantly, he understood,
                    and presumably the Athenians also did, that the disease was
                    contagious; it spread from person to person and those more
                    proximate to the infected were more likely to become sick.
                    Epidemiological modelling is impossible without
                    understanding this fundamental point.
                </p>
                <p>
                    Also remarkable
                    is <a href="https://www.gutenberg.org/files/23700/23700-h/23700-h.htm">The
                    Decameron</a> of Giovanni Boccaccio. It is set against the
                    bubonic plague of the mid-14th century, perhaps the pandemic
                    that killed the greatest proportion of the human population.
                    Boccacio's writing is less factual and more inclined to
                    invoke the supernatural than Thucydides. But it is also more
                    replete with beautiful literary flourishes. Europeans at
                    this time clearly understood that removing themselves from
                    the proximity of the ill reduced their risk of illness.
                    Indeed the ten protagonists of The Decameron did just this,
                    as they take shelter in a villa outside Florence in order to
                    escape the plague. (Because the plague was likely spread by
                    fleas, probably on rats, isolation was not a foolproof way
                    of escaping infection and death.)
                </p>
                <p>
                    The <a href="https://en.wikipedia.org/wiki/The_Ghost_Map">Ghost
                    Map</a> by Steven Johnson tells the story of London's 1854
                    Broad Street cholera outbreak in London and how the efforts
                    of John Snow and Henry Whitehead ushered in scientific
                    responses to epidemics.
                </p>

                <p>
                    A good place to start on modelling are the Wikipedia pages
                    on<a href="https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology">Compartmental
                    Models in Epidemiology</a>
                    and <a href="https://en.wikipedia.org/wiki/William_Farr">William
                    Farr</a>. This <a href="https://fn.bmj.com/content/87/1/F67">article
                    on Farr</a> in the British Medical Journal is also worth
                    reading.
                </p>
                <p>
                    Interesting is the <a href="https://babel.hathitrust.org/cgi/pt?id=njp.32101064041955&view=1up&seq=65">appendix</a>
                    Farr wrote to the Registrar-General of Births, Deaths and
                    Marriages in June 1840. The format of the link is not
                    convenient. Scroll to page 69 to begin reading.
                </p>

                <p>
                    Here are some of the pioneering mathematical papers, but
                    unless you have an acute interest in these kinds of papers,
                    you probably will do no more than swiftly scroll through
                    them, as I did:
                </p>
                <ul>
                    <li>
                        1915-17: An application of the theory of probabilities
                        to the study of a priori pathometry, part <a href="https://royalsocietypublishing.org/doi/epdf/10.1098/rspa.1916.0007">I</a>, <a href="https://royalsocietypublishing.org/doi/epdf/10.1098/rspa.1917.0014">II</a> and <a href="https://royalsocietypublishing.org/doi/epdf/10.1098/rspa.1917.0015">III</a>
                        by Ross and Hudson.
                    </li>
                    <li>
                        1927: <a href="https://royalsocietypublishing.org/doi/epdf/10.1098/rspa.1927.0118">A Contribution to the Mathematical Theory of Epidemics</a>, by Kermack and McKendrick.
                    </li>
                    <li>
                        1932: <a href="https://pubmed.ncbi.nlm.nih.gov/2059742/">Contributions to the mathematical theory of epidemics--II. The problem of endemicity</a> by Kermack and McKendrick.
                    </li>
                    <li>
                        1933: <a href="https://pubmed.ncbi.nlm.nih.gov/2059743/">Contributions to the mathematical theory of epidemics--III. Further studies of the problem of endemicity</a> by Kermack and McKendrick.
                    </li>
                    <li>
                        1956: <a href="https://projecteuclid.org/ebooks/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-Third-Berkeley-Symposium-on-Mathematical-Statistics-and/chapter/Deterministic-and-Stochastic-Epidemics-in-Closed-Populations/bsmsp/1200502553">Deterministic and Stochastic Epidemics in Closed Populations</a> by Kendall.
                    </li>
                </ul>
            </div>
        </aside>
        <p>
            There are many ways to model epidemics, but we can broadly divide
            models into two types: macro and micro. The former typically use a
            set of equations &mdash; either difference or differential ones
            &mdash; to calculate changes in a population, while the latter
            consist of numerous agents, each representing a person with their
            own specific behaviour. Macro models are often also called
            compartmental or equation-based, while micro models are often called
            agent-based or individual-based simulations.
        </p>
        <p>
            At the onset of the Covid pandemic, many websites explained how SIR
            macro models worked. We'll start with that and then try to implement
            an equivalent micro model. We'll then discuss the differences
            between the two types of models and their consequences for
            understanding real-world epidemics. Then we'll implement models of
            HIV and Covid and consider what we can learn about these and other
            infectious diseases from macro and micro models.
        </p>
        <aside>
            <button type="button">Terminology</button>
            <div>
                <p>
                    Terminology is inconsistent across infectious disease
                    literature. For example, Macro, micro, compartmental, SIR,
                    equation-based, deterministic, stochastic: all are used to
                    describe types of models. I find the macro vs micro
                    distinction the most useful here, in part because the terms
                    are antonyms and using them in the source code makes
                    it easier to read. Also while macro models are usually
                    deterministic, they can be implemented stochastically. Micro
                    models can also be implemented deterministically, though a
                    use-case doesn't spring to mind.
                </p>
                <p>
                    Macro and micro models are broad categories and there are
                    all manner of models that borrow ideas from both.
                </p>
                <p>
                    For the most part, I try to stick to terminology used in <a href="https://anintroductiontoinfectiousdiseasemodelling.com/">An
                    introduction to Infectious Disease Modelling</a> by Emilia
                    Vynnycky and Richard G White. This is my reference book for
                    modelling.
                </p>
            </div>
        </aside>

        <h2>A very simple disease</h2>

        <p>
            We start off with a very simple infectious disease. It has the
            following characteristics:
        </p>

        <ol>
            <li>
                A population of at 1,000 people starts off with one infected
                person.
            </li>
            <li>
                Every person in the population is equally likely to be in
                contact with any one else in the population. We call this
                homogeneous mixing. (Changing to heterogeneous mixing makes
                things much more complicated.)
            </li>
            <li>When there are a tiny number of infected people in the
                population, they will on average infect two other people before
                they recover.
            </li>
            <li>
                Infected people on average take 5 days to recover.
            </li>
            <li>
                Once recovered, a person has immunity. They can't become
                infected again and they can't transmit the infection to anyone
                else.
            </li>
        </ol>

        <p>
            No-one dies and there are no births or migration into or out of this
            population, at least for the time period that we model.
        </p>

        <p>
            Characteristic 3 of our model is what's commonly called
            $\underline{R}_0$, or the <em>basic reproduction number</em> in
            epidemiological literature. <a href="https://anintroductiontoinfectiousdiseasemodelling.com/">Vynnycky and
            White</a> write: "$\underline{R}_0$ is defined as the average number
            of secondary infectious persons resulting from a typical infectious
            person following their introduction into a totally susceptible
            population".
        </p>

        <p>The real-world use of $\underline{R}_0$ is much more limited than is
            usually admitted but it's still useful.
        </p>

        <p>
            We call our description above a model world. We can implement both a
            macro or a micro model version of it.
        </p>

        <p>
            In this population we have people who are <b>S</b>usceptible to the
            infection, but not yet infected. There are infected people, and all
            infected people are also <b>I</b>nfectious. We also have <b>R</b>ecovered people.
            That's three compartments: Susceptible, Infectious and Recovered, abbreviated as SIR.
        </p>
        <p>
            We initialise our model so that nearly everyone in the population is
            uninfected and has never had the infection. In other words everyone
            is in the Susceptible compartment and a tiny number are in the
            Infectious compartment.
        </p>
        <p>
            Let's assume the population size is 1000. Then we'll set $S$, the
            number of people in the Susceptible compartment to 999 and $I$, the
            number of people in the Infectious compartment to 1. The number of
            people, $R$, in the Recovered compartment is 0. (Note we do not
            underline ${R}$, the number of recovered people, to differentiate it
            from $\underline{R}_0$, the number of people that each infectious
            person will infect when the epidemic is still very small. I wish
            this was a standard adopted throughout infectious disease
            literature.)
        </p>

        <p>
            All the above is common to both the macro and micro models that we
            implement. Now let's describe specific details of our macro model:
        </p>

        <h3>SIR Macro model using difference equations</h3>

        <p>
            We iteratively update the $S$, $I$ and $R$ compartments with the
            number of people who have moved between them. In our model each
            iteration represents a day in our infectious disease world. These
            equations describe what happens on each iteration:
        </p>

        <p>
            Note that the number of people in our macro model compartments are
            continuous real numbers, not discrete. This is a big difference
            between our macro and micro models.
        </p>

        <p>
            Consider two scenarios: (1) There are very few infected people in a
            population &mdash; nearly everyone is susceptible &mdash; versus (2)
            nearly everyone is infected &mdash; there are few susceptible
            people. In the former scenario, the infected people are much more
            likely to come into contact with susceptible people, infecting some
            of them. In the latter, since there are few susceptible people, the
            average infected person is less likely to come into contact with
            them.
        </p>

        <p>
            It's quite straightforward to capture this as an equation. The number
            of people who become infected on each iteration, or day, of our
            model is a function of S, I and the risk of infection $\lambda$.
            Since all three of these variables change with time, we subscript
            them. This equation describes the flow from $S$ to $I$:

            \begin{equation} S_{t+1}=S_t - \lambda_t S_t \end{equation}
        </p>

        <p>
            So if 10 people are susceptible and 2 of them become infected on an
            iteration, $\lambda$ on that particular iteration is 0.2. But how do we update $\lambda$ on each iteration?
        </p>

        <p>
            Since people mix homogeneously, we have:

            \begin{equation} \lambda_t = \beta I_t \end{equation}

            where

            \begin{equation}
            \beta = {\underline{R}_0 \over {ND}}
            \label{eq:R0}
            \end{equation}

            where $N$ is the population size and $D$ is the average number of
            days a person is infected (5 in our model).
        </p>

        <p>
            The other equations in the model are simple:
        </p>
        <p>
            \begin{equation}
            I_{t+1}=I_t + \lambda_t S_t - rI_t
            \end{equation}

            \begin{equation}
            R_{t+1}=R_t + rI_t
            \end{equation}

            where $r$ is the rate of recovery per day, or $1/5$ in our model.
        </p>

        <p>
            Here is an implementation of this model:
        </p>

        <p>
            <img src="sir.svg" alt="Basic SIR graph">
        </p>


        <div id="macroSIR" class="sir">
            <noscript>You need Javascript enabled to run this webpage's models.</noscript>
        </div>

        <p>
            There are four boxes shown in each model:
        </p>

        <dl>
            <dt>Outputs</dt>
            <dd>
                This shows the population size of each compartment after each
                iteration of a model.
            </dd>

            <dt>Parameters</dt>
            <dd>
                You can change the parameters before running a model. Press the <em>Reset</em> button
                to set the parameters to their original values. So for example, try increasing or
            </dd>

            <dt>Graph</dt>
            <dd>This shows how the compartment population sizes change over
                time.</dd>

            <dt>Population</dt>
            <dd>This shows the status of the individuals in the population. This
                makes much more sense for micro models. In macro models you usually
                have fractions of individuals, so we round off. Also our macro
                models are deterministics so all the individuals in a particular
                compartment are grouped together. </dd>
        </dl>

        <p>
            Adjust the speed slider to make the model run faster or slower.
        </p>

        <p>Click the <em>Run</em> button to run a model. It changes to a <em>Stop</em> button
            while the model is running so that you can interrupt the model. This
            is useful if it's taking too long.</p>


        <h3>Using differential equations</h3>

        <p>
            Modelling using difference equations is often adequate. But there is
            a problem. Let's change our model world so that our disease is
            highly infectious. Let's set $\underline{R}_0$ to 20. Now run the
            model. It goes horribly wrong. By day 5 the number of susceptible
            agents is negative, an impossible situation.
        </p>

        <p>
            The reason this has happened is because infections are happening so
            quickly that our timestep of 1 day is now too large. By day 5
            $\lambda$ becomes greater than 1, resulting in more infections
            occurring than the size of the suceptible population, which is
            absurd.
        </p>
        <p>
            There are two ways to fix such a problem. One would be to have each
            iteration represent a much smaller time unit. You'd have to change
            the value of $D$ appropriately. So if your timestep is 1/10th of a
            day, then $D$ is then set to 50 to represent our new model world.
        </p>
        <p>
            An alternative is to instead use differential equations. Difference
            equations calculate changes to compartments across discrete time
            steps, while a differential equation is continuous.
        </p>

        <p>
            Differential equations express the what the rates of change in
            compartments converge to as the time steps becomes tinier and
            tinier, getting closer and closer to zero. <span class="footnote">A
            rudimentary calculus book can explain this better and in more depth.
            Also, the explanation in
            <a href="https://anintroductiontoinfectiousdiseasemodelling.com/">Vynnycky and
                White</a> is excellent.</span> Instead of using the subscript
            $t$ in our notation, our equations are now functions of time.
        </p>

        <p>
            Recasting our difference equations as differential equations, we have:
        </p>

        <p>
            \begin{equation}
            \frac{dS}{dt} = -\beta I(t) S(t)
            \end{equation}


            \begin{equation}
            \frac{dI}{dt} = \beta I(t) S(t) - r I(t)
            \end{equation}

            and

            \begin{equation}
            \frac{dR}{dt} = r I(t)
            \end{equation}

        </p>

        <p>Here is an implementation of the model using differential equations.</p>

        <div id="macroSIROde" class="sir">
            <noscript>You need Javascript enabled to run this webpage's models.</noscript>
        </div>

        <p>If you run this as is, you end up with almost the same epidemic as
            with our difference equations. The differential equation model model
            converges on just under 80% of the population getting infected,
            while the difference equation version converged on just over 80%
            getting infected. If you were modelling a real world epidemic, it's
            unlikely you'd be bothered by this difference in results because the
            margins of error in the data and parameters are far greater than
            this.
        </p>
        <p>But setting $\underline{R}_0$ to 20, now obtains sensible results.</p>

        <p>Nevertheless, even here there are limitations. Our differential
            equations are being solved using discrete computer hardware and must
            approximate solutions of continuous functions. The simple algorithm
            we use to solve our differential equations also breaks down if we
            set $\underline{R}_0$ too close to 3000 without reducing the time
            step. Of course such a high $\underline{R}_0$ is of no practical
            concern.<span class="footnote">
            To solve differential equations we use the <a href="https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods">Runge Kutta</a>
            algorithm, nicely <a href="https://github.com/giannotr/runge-kutta-js">implemented by Ruben Giannotti</a>
            in Javascript. I have set the step size to 0.01. A more
            sophisticated implementation could <a href="https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods#Adaptive_Runge%E2%80%93Kutta_methods">adapt</a> the
            step size, but this seems unneccessary for our purposes.</span>
        </p>

        <h3>SIR micro model</h3>

        <p>Now let's implement a micro model that approximates the above macro
            model.</p>

        <p>
            A micro model consists of agents and events. An agent typically
            represents a single person in a population. An event typically is
            executed on a subset of agents. There are different ways to implement
            micro models. The methodology described here is simple and fast.
        </p>

        <p> There are three stages to executing our micro models: <em>before</em>
            events, <em>during</em> events and <em>after</em> events.
        </p>
        <p>
            First execute the
            <em>before</em> events. These typically would create and initialise
            the agents, write a report of the initial state of the population
            and perhaps calculate some working variables that won't change once
            the simulation starts.
        </p>
        <p>
            Then iteratively execute the <em>during</em> events until some stop
            condition is met. As with our difference equation macro model, each
            iteration corresponds to our time step. A simple stop condition is
            simply to execute the during events $n$ times, where $n$ is a
            user-defined constant. Typical during events would shuffle the
            agents (to generate more stochasticity), infect some susceptibe
            agents, vaccinate some agents, recover some infected agents, or kill
            some ill agents.<span class="footnote">A different way to do micro
            models is to schedule stochastically ocurring specific events on
            specific agents. I haven't used this methodology and I am currently
            unable to see how to create efficient models using this approach.
            But, that may be simply a factor of my ignorance, and in future I
            may investigate this methodology and, once I understand it better,
            write about it.
            </span>
        </p>
        <p>
            Finally execute the after events which would typically be writing a
            report or creating a CSV file of the outputs.
        </p>

        <p>Here is the structure of our micro models:</p>

        <pre>
  Execute before events
  # Simulation loop:
  Loop n times:
  for each during event, e:
  For each agent, a:
  If e should be applied to a:
  e(a)
  Execute after events
        </pre>

        <p>Here is a micro model for our simple model world.</p>

        <div id="microSIR" class="sir">
            <noscript>You need Javascript enabled to run this webpage's models.</noscript>
        </div>

        <p>Run the two SIR macro models and then run the micro model multiple
            times. What do you notice?</p>

        <p>
            Even with these simple models of our highly idealised model world,
            there are already interesting observations we can make:
        </p>

        <ul>
            <li>
                The macro models obviously gives the same outputs every time.
                They're entirely deterministic. The micro model seldom repeats
                exactly the same outputs.
            </li>
            <li>
                With the parameters used here, the infectious disease in the
                micro model often fails to take off; no one besides the
                originally infected agent becomes infected.
            </li>
            <li>
                The macro models end with about 80% of people in the
                recovery compartment. The micro model epidemic on average has
                far fewer infections. This is because with just one initial
                infection it often fails to "take off".
            </li>
        </ul>

        <p>
            I ran the micro model 100 times. In some simulations, there are no
            new infections. The most number of infections in a simulation was
            856 infections, higher than the macro models. But the mean number of
            total infections across the simulations was only about 47%, much
            lower than the macro models. One thing of real-world consequence
            that this suggests is when an infected person enters a community of
            otherwise entirely uninfected people, there is a great deal of
            chance as to whether an epidemic will occur in that community.
        </p>

        <p>
            During the height of the Covid pandemic, there were many reports
            comparing why many people became infected in one geographic location
            versus another. Such speculation can be useful. The severity of an
            epidemic can be mitigated by timely rational action. But we should
            realise the role of chance; sometimes whether an epidemic explodes
            in one community and dissipates without much consequence in another
            is a matter of nature playing dice.
        </p>

        <p>
            Here are the difference equation SIR macro model (difference
            equations) and the SIR micro model again but with one difference:
            the number of infections in the initial population is 100 instead of
            1.
        </p>

        <p>First the macro model: </p>
        <div id="macroSIR100" class="sir">
            <noscript>You need Javascript enabled to run this webpage's models.</noscript>
        </div>
        <p>Now the micro model: </p>
        <div id="microSIR100" class="sir">
            <noscript>You need Javascript enabled to run this webpage's models.</noscript>
        </div>

        <aside>
            <button type="button">How to run the micro models many times</button>
            <div>
                <p>
                    You could press the Run button on a micro model 100 times
                    and tabulate the outputs each time, but there's a much
                    easier way.
                </p>
                <ol>
                    <li>Open an interactive Javascript console in your browser.
                        On Firefox or Chromium I press CTRL-SHIFT-C and then click
                        on the console tab.
                    </li>
                    <li>
                        Then execute this code:
                        <pre>
          series = EpiMicro.runSimulations(microSIR100, 100);
          EpiMicro.stat(series, -1, 'R', EpiMicro.min);
          EpiMicro.stat(series, -1, 'R', EpiMicro.max);
          EpiMicro.stat(series, -1, 'R', EpiMicro.mean);
                        </pre>
                        The first line runs the microSIR100 model 100 times. The
                        next three lines get the min, max and mean of the final
                        value of the recoveries in the model.
                    </li>
                    <li>
                        To change the initial values of the model's
                        compartments, you can do something like this:
                        <pre>
          // Change the number of initial susceptible agents to 990
          microSIR100.compartments.S = 990;
          // Change the number of initial infected agents to 10
          microSIR100.compartments.I = 10;
                        </pre>
                    </li>
                    <li>
                        To change the model's parameters, you can first view them like so:
                        <pre>
          microSIR.parameters;
                        </pre>
                        And then modify them as appropriate.
                    </li>
                </ol>
                <p>
                    You can do the above with any of the models. All the model
                    names and their descriptions are stored in the
                    EpiUI.modelRegister variable. Obviously the macro models
                    give the same min, max and mean every time you run them.
                </p>
            </div>
        </aside>

        <p>
            Now running the micro model 100 times yields a mean of 843
            infections per simulation &mdash; you may get a slightly different
            answer each time you run it &mdash; about the same as the macro
            model's 842. The minimum number of infections in these 100
            simulations was 767 and the maximum was 892. Again, your outputs
            will likely differ a little.
        </p>

        <p>
            Tinker with the other parameters, $\underline{R}_0$ and $D$, to see
            how changing these changes the models' outputs.
        </p>

        <h2><em><u>R</u><sub>0</sub></em>: Its uses and limits</h2>

        <p>
            Sometimes highly technical abstract mathematical concepts become
            part of the popular imagination. Perhaps the clearest example is
            Einstein's equation $E=MC^2$. During the first couple of years of
            the Covid pandemic it was $\underline{R}_0$. While it is a helpful
            concept, it's usefulness has been somewhat overstated and it is
            often misunderstood.
        </p>

        <p>
            What exactly is $\underline{R}_0$? Imagine introducing a single
            infected person &mdash; the index case &mdash; into a community
            where every single person is susceptible. Moreover imagine that
            everyone has the same risk of infection and that everyone mixes
            randomly. In this idealised scenario the number of people infected
            by the index case is $\underline{R}_0$. In all real-world situation
            $\underline{R}_0$ is at most an approximation.
        </p>
        <p>
            The following graphs are obtained by running the differential
            equation SIR model with different values of $\underline{R}_0$.
        </p>
        <figure id="fourR0graphs">
            <img src="fourGraphsOfR0.webp" alt="Four graphs showing infections with different values of R0">
            <figcaption>
                These graphs show the number of infections by week over 96 weeks
                with four different values of $\underline{R}_0$. From top to
                bottom the values of $\underline{R}_0$ are 1, 2, 4 and 8. The y-axis
                plots infections. The x-axis is the week number.
            </figcaption>
        </figure>

        <p>
            Note how the higher the value of $\underline{R}_0$, the higher the
            peak number of infections and the longer the epidemic's tail,
            rendering the curve less and less like the standard normal curve.
        </p>
        <p>
            $\underline{R}_0$ can be generalised to $\underline{R}_t$, the
            average number of people infected by an infected person on a
            specific timestep $t$. Given $\underline{R}_0$ and $s$, the
            proportion of the total population that remains susceptible, we have
            the following equation:
        </p>

        <p>
            \begin{equation}
            \underline{R_t} = s \underline{R_0}
            \end{equation}
        </p>

        <p>
            The salient feature of $\underline{R_t}$ is that if it's below 1 the
            number of new cases is declining and if it's above 1 the number of
            new cases is increasing.
        </p>

        <p>
            A slight misconception during the height of the Covid pandemic was
            to ascribe this feature to $\underline{R_0}$, instead of
            $\underline{R_t}$, but if $\underline{R_0}$ was below 1 there would
            have been no Covid pandemic. (I say "slight", because while people
            used the term $\underline{R_0}$, it was usually obvious in context
            that they were talking about $\underline{R_t}$ and such minor
            reductions in accuracy for the sake of simplicity are forgivable
            when explaining complex topics to the public.)
        </p>

        <p>
            A more serious misconception during the height of the pandemic was
            the concept of herd immunity. Many implied that once herd immunity
            was reached, that was pretty much the end of the epidemic. Putting
            aside that the SARS-CoV-2 virus keeps mutating, with the consequence
            that recovered people become susceptible again, even in its
            idealised meaning herd immuunity does not mean an epidemic has
            ended, or is even necessarily close to the end.
        </p>

        <p>
            The Herd Immunity Threshold is simply the peak of the above graphs.
            It is the proportion of the population which is immune when the
            number of new infections begins to decline, or when
            $\underline{R_t}$ goes below one, and is given by this equation:
        </p>

        <p>
            \begin{equation}
            1 - {1 \over \underline{R_0}}
            \end{equation}
        </p>

        <p>
            Related to this is the proportion of the population that remains
            susceptible when $\underline{R_t}$ goes below one. This is simply
            the second term in the Herd Immunity Threshhold equation:
        </p>

        <p>
            \begin{equation}
            1 \over \underline{R_0}
            \end{equation}
        </p>


        <p>
            The Herd Immunity Threshold is the target proportion of the
            population vaccination programmes aims to reach to suppress an
            infectious disease, such as measles for example. During the height
            of the Covid pandemic, But the problem with \underline{R_0} and
            \underline{R_t} is that they are easy to define and calculate in our
            idealised SIR model. They are hard to calculate in micro models or
            even complex macro models. And they are extremely hard to estimate
            in real world epidemics, which usually progress in fits and starts
            and not the nice smooth curves of our macro models.
        </p>

        <h2>Adding an exposure compartment</h2>

        <p>
            Let's get a bit more complicated. We change our model world so that
            there's an exposure compartment before an infectious one. When
            exposed a person is infected, but not infectious. In our model world
            the average exposure period is two days. This is an SEIR model.
        </p>

        <p>
            <img src="seir.svg" alt="SEIR graph">
        </p>

        <p>
            Here are the difference equations:
        </p>

        <p>
            \begin{equation} S_{t+1} = S_t - \beta I_t S_t \end{equation}

            \begin{equation} E_{t+1} = E_t + \beta I_t S_t - f I_t \end{equation}

            \begin{equation} I_{t+1} = I_t + f I_t - r I_t \end{equation}

            \begin{equation} R_{t+1} = R_t + r R_t \end{equation}
        </p>

        <p>
            Here's the macro model version of SEIR using difference equations:
        </p>

        <div id="macroSEIR" class="sir">
            <noscript>You need Javascript enabled to run this webpage's models.</noscript>
        </div>

        <p>
            Here are the differential equations for the SEIR model:
        </p>

        <p>
            \begin{equation}
            \frac{dS}{dt} = -\beta I(t) S(t)
            \end{equation}

            \begin{equation}
            \frac{dE}{dt} = \beta I(t) S(t) - f I(t)
            \end{equation}

            \begin{equation}
            \frac{dI}{dt} = (f - r) I(t)
            \end{equation}

            \begin{equation}
            \frac{dR}{dt} = r I(t)
            \end{equation}
        </p>

        <p>
            Here's the macro model version of SEIR using differential equations:
        </p>

        <div id="macroSEIROde" class="sir">
            <noscript>You need Javascript enabled to run this webpage's models.</noscript>
        </div>

        <p>
            Here's the micro model version of SEIR which attempts to match the
            difference equation macro model as closely as possible.
        </p>
        <div id="microSEIR" class="sir">
            <noscript>You need Javascript enabled to run this webpage's models.</noscript>
        </div>

        <p>
            I ran the difference equation macro model once and the micro model
            1,000 times with the number of initial exposures set to 1, 10, 50 and
            100, and the initial susceptibles equal to 999, 990 950 and 900
            respectively.
        </p>
        <p>
            Below are the results. As usual, because the micro model is
            stochastic, your results will probably differ a little.
        </p>

        <div class="epi-table">
            <table>
                <tr>
                    <th>
                    </th>
                    <th>
                        Macro model<br>(difference eq)
                    </th>
                    <th colspan="3">
                        Micro model<br>(1000 simulations)
                    </th>
                </tr>
                <tr>
                    <th>
                        Exposed at start
                    </th>
                    <th>
                        Infections
                    </th>
                    <th>
                        Mean
                    </th>
                    <th>
                        Min
                    </th>
                    <th>
                        Max
                    </th>
                </tr>
                <tr>
                    <td>
                        1
                    </td>
                    <td>
                        796
                    </td>
                    <td>
                        382
                    </td>
                    <td>
                        1
                    </td>
                    <td>
                        856
                    </td>
                </tr>
                <tr>
                    <td>
                        10
                    </td>
                    <td>
                        808
                    </td>
                    <td>
                        803
                    </td>
                    <td>
                        28
                    </td>
                    <td>
                        879
                    </td>
                </tr>
                <tr>
                    <td>
                        50
                    </td>
                    <td>
                        822
                    </td>
                    <td>
                        819
                    </td>
                    <td>
                        729
                    </td>
                    <td>
                        891
                    </td>
                </tr>
                <tr>
                    <td>
                        100
                    </td>
                    <td>
                        838
                    </td>
                    <td>
                        837
                    </td>
                    <td>
                        736
                    </td>
                    <td>
                        915
                    </td>
                </tr>
            </table>
        </div>
        <p>
            The results are consistent with what we see for the SIR models.
        </p>

        <h2>The measles cycle</h2>

        <p>Measles is an interesting but frustrating infectious disease to
            model. It shows that the story of infectious diseases can often be
            more complicated than the approximately normal curve trajectory that
            William Farr posited.
        </p>

        <p>
            This graph shows the oscillating nature of measles in England and
            Wales from 1950 to 1979. It is copied from
            <a href="https://pubmed.ncbi.nlm.nih.gov/7085179/">Fine and Clarkson, 1982</a> (<a href="https://sci-hub.st/https://pubmed.ncbi.nlm.nih.gov/7085179/">full paper on Sci-hub</a>).
            Note how the epidemic returns approximately every two years. The
            arrow shows when the national measles vaccination programme was
            introduced, resulting in much smaller epidemics in subsequent years.
        </p>

        <figure>
            <img src="MeaslesEnglandAndWales.webp" alt="Graph of measles in England and Wales">
            <figcaption>
                Source: <a href="https://pubmed.ncbi.nlm.nih.gov/7085179/">Measles in England and Wales--I: An analysis of factors
                underlying seasonal patterns</a> by Fine and Clarkson, Int J
                Epidemiol. 1982 Mar;11(1):5-14. doi: 10.1093/ije/11.1.5.
            </figcaption>
        </figure>

        <p>
            As Fine and Clarkson explained, there were two theories to try and
            explain this. One was that the measles virus mutated over time, with
            a consequent decline in immunity and resurrection of the epidemic.
            The other, now more accepted theory &mdash; but not without
            controversy because the data doesn't fit either theory as well as
            epidemiologists would like &mdash; is that never-before infected
            children entering schools provide a new susceptible population for
            the epidemic to spike. In between spikes, there are still measles
            cases, but in such low numbers that they largely go undetected.
        </p>

        <p>
            Fine and Clarkson presented a set of difference equations, very
            similar to the SIR model. (Brian Williams has published useful <a href="http://www.ici3d.org/DAIDD2016/Materials/Brian%20Williams%20What%20is%20Science.pdf">slides</a>
            explaining various models, including this model.) I've implemented
            a model only superficially different to theirs.
        </p>

        <p>
            Our model world is a school with a thousand children. There are five
            grades so turnover is about 20% a year. We will assume the
            infectious period with measles is about two weeks (this isn't
            accurate but good enough for our over-simplified purposes), and this
            is our time-step. We set $\underline{R_0}$ to 0.
        </p>
        <p>
            In our model that implements this model world there are just three
            compartments: $S$, $I$ and $R$. $N$ is the constant population size
            ($S+I+R$) and \beta is the population turnover rate. Here are the
            difference equations:

            \begin{equation} I_{t+1} = \underline{R}_0 I_t {S_t \over N}
            \end{equation}

            \begin{equation} S_{t+1} = S_t - I_{t+1} + \beta N \end{equation}

            \begin{equation} R_{t+1} = R_t + I_t - \beta N \end{equation}
        </p>

        <p>
            This is a simple model but it's also unstable. Set $\underline{R}_0$
            a bit high and either $S$ or $R$ goes below zero and the model falls
            apart. So I've sligthly adapted the code for the above equations to
            not reduce $S$ or $R$ below zero. This keeps the model stable.
        </p>

        <div id="macroMeasles" class="sir">
            <noscript>You need Javascript enabled to run this webpage's models.</noscript>
        </div>

        <p>Notice the oscillations in measles cases every two or so years
            generated by the model. Adjust the value of $\beta$ and rerun the
            model to see how the oscillation period changes.
            <span class="footnote">It may be easier to view this graph by clicking on S and R in
                the graph legend, thus switching them off.</span>
        </p>
        <p>
            Also note that while $\beta$ determines the oscillation period while
            $\underline{R}_0$ determines the peak number of infections.
        </p>

        <p>
            On the face of it, this appears to capture the dynamics of measles
            epidemics. But here is a nearly equivalent micro model version.
        </p>

        <div id="microMeasles" class="sir">
            <noscript>You need Javascript enabled to run this webpage's models.</noscript>
        </div>

        <p>
            Notice how the epidemic disappears. This is because in the macro
            model, which uses continuous variables, the number of infections
            never quite gets to zero, so equation 17 is always a positive
            number, albeit often a very tiny one. This means the epidemic will
            eventually resurrect in the macro model. But infection in the micro
            model is an all or nothing discrete affair. An agent is either
            infected or not. Quite quickly, the number of infections declines to
            exactly zero, and the epidemic cannot resurrect itself.
        </p>
        <p>
            I've addressed this by creating a parameter, $r$, or Random
            Infections, that specifies the probability of randomly infecting an
            agent on each iteration. Try running the model with different value.
            The length of the period between epidemic peaks is determined by
            it.
        </p>

        <p>
            Do these models capture the dynamics of the real-world situation or
            do we simply have a set of equations (or rules in the micro model)
            that happen to approximate the infection distribution of measles?
            Where, for instance, did all the measles go in the non-epidemic
            years? I don't know the answer, and the models don't tell us. I find
            this unsatisfying; better models of measles are needed than this.
        </p>

        <aside>
            <button type="button">Pandemic flu and the quality of data</button>
            <div>
                <p>
                    The 1918/19 global flu pandemic was one of the worst in
                    history. The table below shows recorded deaths in India's
                    Bombay Presidency.
                </p>


                <figure>
                    <img src="RegisteredDeathsBombay-1918-1919.webp" alt="Registered deaths in Bombay Presidency 1918-1919">
                    <figcaption>
                        Source: <a href="https://pubmed.ncbi.nlm.nih.gov/11617178/">The
                        1918-1919 Influenza Pandemic &mdash; The Indian
                        Experience</a> by ID Mills,
                        Indian Econ Soc Hist Rev. 1986;23(1):1-40. doi: 10.1177/001946468602300102.
                    </figcaption>
                </figure>

                <p>
                    This table is astonishing. First, the scale of death is hard
                    to comprehend. If we assume the background death rate before the
                    influenza struck in August 1918 was the average of May to July 1918
                    then the number of recorded deaths due to the epidemic was well over
                    1 million, most of those in just two months, October and November.
                    Second, in 1918 the civil service &mdash; despite being hit by this
                    massive disaster, as well as a world war that was already straining
                    the Indian and British populations &mdash; was able to maintain
                    death records with a completion rate that is still better than many
                    countries in 2023. (Incidentally, the wave that struck Bombay in
                    August 1918 was, according to <a href="https://pubmed.ncbi.nlm.nih.gov/11617178/">Mills</a>,
                    the second one. The first struck in June. It's unclear to me whether
                    the absence of a spike in mortality in June and July is due to
                    delayed reporting of deaths or that the first wave was not
                    especially virulent, or some other reason.)
                </p>
                <p>
                    Certainly no previous pandemic was chronicled in such quantitative
                    depth. And yet estimating the number of global or even Indian deaths
                    from the flu pandemic is hard and controversial. They range from
                    fewer than 20 million to over 100 million, none totally implausible.
                    (My own bias is towards the lower end of the scale.)
                </p>
                <p>
                    Let's do some crude calculations:
                </p>
                <ul>
                    <li>
                        The Bombay Presidency under the British Raj had a population of
                        27 million or so according to the <a href="https://dspace.gipe.ac.in/xmlui/bitstream/handle/10973/18950/GIPE-015153-Contents.pdf?sequence=2&isAllowed=y">1911 census</a>,
                        so let's say it was 30 million in 1918 on the eve of the
                        pandemic.
                    </li>
                    <li>
                        Using the above table, the excess deaths in the Bombay
                        Presidency were 1.068 million. That gives a mortality of 3.8%.
                    </li>
                    <li>
                        The global population in 1918 was about 1.8 billion. Projecting
                        what happened in the Bombay Presidency to the planet, we get
                        about 106 million deaths globally.
                    </li>
                </ul>

                <p>
                    This is implausible. The Bombay Presidency is not a representative
                    sample of what happened on average. Bombay was hit especially hard
                    by the pandemic. Besides being overcrowded and people living in
                    ghastly conditions, Bombay's docks served as a port for World War I
                    soldiers. This traffic was quite possibly one of the main drivers of
                    the epidemic. If anything, this shows that one must beware of crude
                    calculations of pandemic deaths.
                </p>

                <p>There have been much more sophisticated efforts.
                    <a href="">Spreeuwenberg et al. (2018)</a> write:
                </p>

                <blockquote>
                    "The [global death] burden [of the 1918/19 influenza pandemic] has
                    been estimated many times over the past 100 years, and the estimated
                    burden gradually has increased. One of the oldest estimates was made
                    by <a href="https://scholar.google.com/scholar_lookup?title=Epidemic%20Influenza%3A%20A%20Survey&author=EO%20Jordan&publication_year=1927&book=Epidemic%20Influenza%3A%20A%20Survey"> Jordan</a> in 1927, who estimated the global burden to be
                    approximately 21.6 million deaths. <a href="https://pubmed.ncbi.nlm.nih.gov/2021692/">Patterson and Pyle</a>, in 1991,
                    estimated the burden to be 30 million (ranging from 24.7 million to
                    39.3 million). In 2002, <a href="https://pubmed.ncbi.nlm.nih.gov/11875246/">Johnson and Mueller</a> reported
                    a range of 50 million to 100 million deaths, with 50 million closer
                    to the results from the studies they cited, and 100 million being
                    the upper limit, because they believed 50 million to be an
                    underestimate."
                </blockquote>

                <p>
                    Spreeuwenberg et al. estimate just over 17 million deaths and not
                    more than 25 million. "Our results suggest the global death impact
                    of the 1918 pandemic was important but not as severe as most
                    frequently cited estimates," they write.
                </p>

                <p>
                    Estimating the number of deaths is difficult enough; estimating the
                    number of infections is very much harder. And how does one even
                    begin to estimate $\underline{R}_0$ with such imperfect data and
                    such wide disagreement? The point here is not to weigh into this
                    debate which would require considerable study and expertise. Rather
                    it is to show how imperfect our knowledge is of the spread and
                    number of deaths brought by infectious diseases.
                </p>

                <p>
                    This remains true of epidemics today. The Economist has been
                    attempting to <a href="https://www.economist.com/graphic-detail/coronavirus-excess-deaths-estimates">estimate
                    the number of excess deaths caused by Covid globally</a>. As of 28
                    February 2023, the authors state: "We find that there is a 95%
                    chance that the true value lies between 16.5m and 27.2m additional
                    deaths." Besides being a wide range of the number of deaths of the
                    most documented and studied pandemic in history, one is struck, when
                    delving into their analysis, by the poor quality of data from many
                    countries.
                </p>

                <p>
                    If we compare The Economist analysis to the lower bound 1918 flu
                    mortality estimates, it is possible that Covid may have killed more
                    people. But the global population is about four times greater now
                    and, also, the age distribution of Covid deaths was very much older
                    than the flu pandemic. That the death tolls from the 1918/19
                    influenze pandemic and Covid are catastrophically high is
                    indisputable. But precise estimates should be treated with great
                    caution. The same can be said for the Antonine Plague (165-180AD),
                    the Justinian Plague (541-549AD), the Black Death (1346-1353),
                    smallpox through the aeons, tuberculosis through the millenia, HIV
                    over the past 40 years, and a whole bunch of other infectious
                    maladies. Modellers should be modest.
                </p>
            </div>
        </aside>
        <h2>
            Modelling when to start HIV treatment
        </h2>

        <p>
            In the late 2000s until 2015 there was a feisty discussion in the
            HIV field about the optimal time for eople with HIV to start
            antiretroviral treatment. These pills taken daily for life reduce
            the number of HIV virions in the blood of people with this
            infection, usually to undetectable levels. This brings two
            advantages: (1) it extends life-expectancy to almost normal and (2)
            it reduces the risk of transmitting the virus to others, though this
            was not known with much confidence until a large clinical trial
            confirmed it in 2011.
        </p>
        <p>
            The ideal time to start treatment wasn't clear because of three
            concerns: (1) the side effects of the drugs, (2) if drug resistance
            developed quickly a person would lose the benefit of the drug
            regimen, so starting later might extend the period of drug
            efficacy longer, and (3) the cost of the drugs.
        </p>
        <p>
            In 2015
            a <a href="https://www.nejm.org/doi/full/10.1056/nejmoa1506816">large
            clinical trial</a> showed the benefit of starting
            treatment as soon as a person was diagnosed were substantial.
            Moreover drug resistance and serious side effects with newer
            antiretroviral regimens have become minor problems. Nowadays medical
            guidelines recommend that people with HIV should start treatment
            when they are diagnosed; no need to wait.
        </p>

        <p> Nevertheless in the late 2000s all of this was unclear. World Health
            Organisation researchers (Granich et al. 2009) published models in <a href="https://www.sciencedirect.com/science/article/abs/pii/S0140673608616979">The Lancet</a> that
            showed that a policy of actively testing and immediately treating
            people with HIV in South Africa, the country with the most number of
            people with this virus, would reduce its HIV prevalence to a
            negligible level in 50 years.
        </p>
        <p>
            The paper certainly made a splash, evoking voiceferous discussion.
            According to Google Scholar it has been cited over 2,300 times. I
            suspect that until the Covid pandemic it was the most highly
            cited infectious disease model ever.
        </p>
        <p>
            The graphic below from the paper in The Lancet, describes one of
            their models.
        </p>

        <figure>
            <img src="GranichEtAlModel.webp" alt="Model by Granich et al">
            <figcaption>From <a href="https://www.sciencedirect.com/science/article/abs/pii/S0140673608616979">Granich et al. 2009</a>.
                The authors explain:<br>
                "N represents population aged 15 years and above. People enter
                into the susceptible class (S) at a rate $βN$, become infected at
                a rate $λSJ/N$, progress through four stages of HIV (I<sub>i</sub>,
                i=1–4) at a rate ρ between each stage, and then die (D). The
                background mortality rate is μ and people are tested at a rate
                τ. If they are tested and put onto antiretroviral treatment
                (ART), they move to the corresponding ART box A<sub>i</sub>
                (i=1–4), where they progress through four stages at a rate σ and
                then die. The term governing transmission contains the factor
                $Jα(I_i +εA_i)$ where ε allows for the fact that people receiving
                ART are less infectious than are those who are not. They might
                also stop treatment or the treatment might become ineffective,
                in which case they return to the corresponding non-ART state at
                a rate τ. To allow for heterogeneity in sexual behaviour and for
                the observed steady state prevalence of HIV, we let the
                transmission decrease with the prevalence, P. If n=1, the
                decrease is exponential; if n=∞, the decrease is a step
                function. Both have been used in previous models."
            </figcaption>
        </figure>

        <p>
            This is a much more complex model than our SEIR or measles ones. It
            accounts for population growth and deaths. The model specification
            has 10 compartments and another 10 parameters. Here is a macro model
            (using difference equations) implementation of Granich et al.
        </p>

        <div id="macroGranichEtAl" class="sir">
            <noscript>You need Javascript enabled to run this webpage's models.</noscript>
        </div>

        <p>
            In the results table, the total number of infections (the sum of
            compartments I1 through I4 and A1 through A4) is tracked in the
            column with the heading I. Try adjusting the parameters, especially
            τ, and rerunning the model to see how the course of the epidemic
            changes, particularly the S (susceptibles), D (deaths) and I
            (infections) columns. For example set τ to 0.00 (in other words no
            treatment takes place) and notice how the population declines, and
            infections and deaths skyrocket.
        </p>

        <p>We can quite easily implement a microsimulation version of this.</p>
        <div id="microGranichEtAl" class="sir">
            <noscript>You need Javascript enabled to run this webpage's models.</noscript>
        </div>

        <div class="epi-table">
            <table>
                <tr>
                    <th>
                        &nbsp;
                    </th>
                    <th colspan="3">
                        Macro
                    </th>
                    <th colspan="3">
                        Micro
                    </th>
                </tr>
                <tr>
                    <th>
                        τ
                    </th>
                    <th>
                        Susc.
                    </th>
                    <th>
                        Inf.
                    </th>
                    <th>
                        Dead
                    </th>
                    <th>
                        Susc.
                    </th>
                    <th>
                        Inf.
                    </th>
                    <th>
                        Dead
                    </th>
                </tr>
                <tr>
                    <td>
                        0
                    </td>
                    <td>
                        724
                    </td>
                    <td>
                        477
                    </td>
                    <td>
                        374
                    </td>
                    <td>
                        681
                    </td>
                    <td>
                        365
                    </td>
                    <td>
                        470
                    </td>
                </tr>
                <tr>
                    <td>
                        0.15
                    </td>
                    <td>
                        1165
                    </td>
                    <td>
                        279
                    </td>
                    <td>
                        116
                    </td>
                    <td>
                        1145
                    </td>
                    <td>
                        122
                    </td>
                    <td>
                        281
                    </td>
                </tr>
                <tr>
                    <td>
                        0.3
                    </td>
                    <td>
                        1194
                    </td>
                    <td>
                        268
                    </td>
                    <td>
                        94
                    </td>
                    <td>
                        1188
                    </td>
                    <td>
                        96
                    </td>
                    <td>
                        269
                    </td>
                </tr>
            </table>
        </div>

        <p>
            While I have done my best to match the two models, the course of the
            epidemic is now highly non-linear and I haven't achieved
            near-perfect matching like in the SIR and SEIR models. Nevertheless,
            in infectious disease modelling we are seldom, if ever, interested
            in precise predictions; we merely hope for plausible approximations.
            So the differences between the outputs of the two models appear to
            be inconsequential.
        </p>

        <aside>
            <button type="button">Can models predict the future?</button>
            <div>
                <h5>The first Covid models</h5>

                <p>
                    In March 2020 – a few months after the appearance of the Covid
                    pandemic &mdash; a <a href="https://www.imperial.ac.uk/media/imperial-college/medicine/mrc-gida/2020-03-16-COVID19-Report-9.pdf">micro model</a> by
                    Neil Ferguson and his team at Imperial College in the UK was
                    widely reported in the media. The modellers considered how various
                    interventions, such as isolation, quarantining, social distancing
                    and school and university closures would affect the spread of
                    SARS-CoV-2 and the pressure on hospitals.
                </p>

                <p>
                    Their report is detailed and nuanced. There is extensive discussion
                    about mitigating the effects of Covid — reducing $\underline{R_t}$
                    but not below 1 — versus suppressing it completely — reducing
                    $\underline{R_t}$ below 1. It also had to make a plethora of
                    assumptions given how little was understood about Covid at the time.
                </p>

                <p>
                    Unsurprisingly, as with any model that tries to predict the future,
                    it got some things wrong, such as the time period over which Covid
                    would peak. It also didn’t consider that SARS-CoV-2 would mutate and
                    that the epidemic would return in waves of differing infectiousness
                    and virulence.
                </p>

                <p>
                    The report concludes that social distancing would have the largest
                    impact. Combining this with isolating infected people and school and
                    university closures had “the potential to suppress transmission
                    below the threshold of $\underline{R} = 1$”, the authors wrote.
                </p>

                <p>
                    They also pointed out that, “to avoid a rebound in transmission”,
                    these policies would need to be maintained until large stocks of
                    vaccine became available. They pessimistically predicted this would
                    be 18 months or more, but in fact vaccines became available near the
                    end of 2020, although most countries wouldn’t start rolling them out
                    until 2021.
                </p>
                <p>
                    The authors recommended using hospital surveillance to switch these
                    measures on and off. Importantly they wrote: “Given local epidemics
                    are not perfectly synchronised, local policies are also more
                    efficient and can achieve comparable levels of suppression to
                    national policies while being in force for a slightly smaller
                    proportion of the time.”
                </p>
                <p>
                    They were cautious:
                </p>

                <blockquote>
                    "However, there are very large uncertainties around the transmission
                    of this virus, the likely effectiveness of different policies and
                    the extent to which the population spontaneously adopts risk
                    reducing behaviours. This means it is difficult to be definitive
                    about the likely initial duration of measures which will be
                    required, except that it will be several months. Future decisions on
                    when and for how long to relax policies will need to be informed by
                    ongoing surveillance."
                </blockquote>

                <p>
                    They also considered mitigation instead of suppression:
                </p>

                <blockquote>
                    "Our results show that the alternative relatively short-term
                    (3-month) mitigation policy option might reduce deaths seen in the
                    epidemic by up to half, and peak healthcare demand by two-thirds.
                    The combination of case isolation, household quarantine and social
                    distancing of those at higher risk of severe outcomes (older
                    individuals and those with other underlying health conditions) are
                    the most effective policy combination for epidemic mitigation."
                </blockquote>

                <p>
                    There is very little emphasis on actual results. The same is true
                    for Imperial College's <a href="https://www.imperial.ac.uk/news/196234/covid-19-imperial-researchers-model-likely-impact/">news summary</a> of
                    the report for the general public. This seems to be a sensible
                    approach. No model in March 2020, less than three months after Covid
                    had been discovered, could rely on sufficient accurate knowledge to
                    predict the future with any realistic accuracy. Even when diseases
                    are well-understood, and slow moving, like TB and HIV, it is very
                    hard to predict future infections and mortality with much accuracy.
                </p>
                <p>
                    What models can do, and what the Imperial College model did, is show
                    the approximate magnitude of certain interventions on mitigating or
                    suppressing infectious outbreaks.
                </p>
                <p>
                    Yet the Imperial College model was widely criticised, especially by
                    those with an ideology opposed to stringent government intervention.
                </p>

                <p>
                    In April 2020, the US-based Cato Institute <a href="https://www.cato.org/blog/how-one-model-simulated-22-million-us-deaths-covid-19">lambasted</a> the
                    model. It criticised its pessimistic predictions, which hadn’t come
                    close to being true by that time. "Neither the high infection rate
                    nor the high fatality rate holds up under scrutiny.” The article,
                    which echoed the Cato Institute’s opposition to lockdowns or any
                    stringent government measures to control the epidemic, stated:
                </p>
                <blockquote>
                    "The trouble with being too easily led by models is we can too
                    easily be misled by models. Epidemic models may seem entirely different
                    from economic models or climate models, but they all make terrible
                    forecasts if filled with wrong assumptions and parameters.”
                </blockquote>

                <p>
                    Much is made of the model’s estimate of 2.2 million Covid-19 deaths
                    in the US in the absence of any interventions, something the
                    modelling report correctly did <strong>not</strong> emphasise at all.
                </p>

                <p>
                    The critique is not entirely unfair: it makes the point that the
                    model and the response of governments didn’t account for some people
                    voluntarily taking action to reduce their risk of infection. And the
                    long-term repurcussions of closing schools and universities for long
                    periods of time are still being debated, and felt.
                </p>
                <p>
                    But much of the Imperial College model did in fact stand up to
                    scrutiny in the long run. There have been over 1.1 million Covid
                    deaths in the US. At least <a href="https://www.commonwealthfund.org/publications/issue-briefs/2021/dec/us-covid-19-vaccination-program-one-year-how-many-deaths-and">one study</a> estimated
                    that vaccines saved over a million lives. This suggests that Covid
                    in the US, left unchecked, may well have claimed about 2 million
                    lives. But the Imperial College model did not get the timeframe or
                    wavy nature of the pandemic right.
                </p>
                <p>
                    Even so, this is not the point. The modellers didn’t emphasise the
                    precision of their measurements. That wasn’t the point of their
                    model. Their aim was rather to reach broad conclusions: that if the
                    pandemic was left unmitigated or unsuppressed it would have a much
                    more devastating impact. On this they were right.
                </p>
                <p>
                    In South Africa the earliest released <a href="https://www.groundup.org.za/article/heres-what-models-predict-about-covid-19/">government model</a> was
                    widely criticised by opponents of lockdowns, who wanted to minimise
                    the pandemic’s effects to support their arguments. The model had, a
                    quickly done back-of-a-cigarette-box, feel to it. Like the Imperial
                    College model it didn’t account for mutations and the consequent
                    wavy nature of the disease, and it also predicted a much swifter
                    unfolding of things. But, frankly, given the state of knowledge at
                    the time, a simple SIR-type model was arguably sufficient to make
                    the point that reducing social contacts would slow the pandemic.
                </p>
                <p>
                    Given the heated ideological disputes in response to Covid, perhaps
                    there was no way early modellers could have escaped criticism, even
                    if they had miraculously estimated the trajectory of the pandemic
                    with pinpoint accuracy. Nevertheless modellers might consider
                    explicitly explaining upfront that it is the broad conclusions
                    rather than the specific estimates of their model that are
                    important.
                </p>
                <p>
                    Also, when an epidemic’s parameters are hard to know with precision
                    or vary a lot from place to place, modellers should perhaps consider
                    running thousands of simulations that randomly perturb the
                    parameters within reasonable ranges. Then we can present multiple
                    possible scenarios to the public. Though this must be done in a way
                    that emphasises the more likely scenarios and that does not
                    overwhelm the public with a plethora of possibilities. Done
                    properly, I hope this acknowledgement of our ignorance may actually
                    gain greater public confidence in the modelling process.
                </p>

                <h5>The Thembisa model</h5>

                <p>
                    Since the 1990s models to predict the trajectory of the HIV epidemic
                    in South Africa have been useful for estimating medical need and
                    cost. The most widely acclaimed of these was the Actuarial Society
                    of South Africa model, predominantly developed by Rob Dorrington.
                    This was enhanced, mainly by Leigh Johnson into what is now the
                    <a href="https://thembisa.org/">Thembisa model</a>.<span class="footnote">The
                        full citations for the model are: <em>Johnson
                        LF, May MT, Dorrington RE, Cornell M, Boulle A, Egger M and Davies
                        MA. (2017) Estimating the impact of antiretroviral treatment on
                        adult mortality trends in South Africa: a mathematical modelling
                        study. PLoS Medicine. 14(12): e1002468.</em> and <em>Johnson LF,
                        Dorrington RE, Moolla H. (2017) Progress towards the 2020
                        targets for HIV diagnosis and antiretroviral treatment in South
                        Africa. Southern African Journal of HIV Medicine.18(1): a694</em></span>
                </p>
                <p>
                    The Thembisa model is extremely complex and carefully calibrated to
                    match known data points. It uses a monthly timestep and produces a
                    huge number of outputs, including the South African population size,
                    number of deaths, number of deaths from HIV, the number of people
                    with HIV, the number of new infections and more. This is all broken
                    down by age group and sex. Thembisa includes several interventions
                    including antiretroviral treatment, male medical circumcision,
                    pre-exposure prophylaxis and the prevention of mother-to-child
                    transmission.
                </p>
                <p>
                    South Africa's latest available census results are from
                    2011. A census was conducted in 2022 but has not yet been
                    published (and there are concerns about how well the census
                    was conducted). Because the census data is so old I (and
                    others) use the population size, life expectancy and other
                    demographic outputs of Thembisa when writing about these
                    things. The model, which is meticulously constructed, has de
                    facto become the definitive source of population estimates.
                    This is despite my cautions about using models to predict
                    the future accurately. But it's justified in this case
                    because (1) the dynamics of HIV are currently still better
                    understood than Covid and the epidemic fluctuates at a
                    stately pace compared to Covid, and (2) the Thembisa model
                    has decades of careful work behind it.
                </p>

            </div>
        </aside>

        <h2>Covid: Not an easy disease to model</h2>

        <p>
            Here is a model world that tries to capture the nature of a Covid
            outbreak in a small community:
        </p>
        <ul>
            <li>
                To start with we have a large susceptible (S) population and
                a few people who are infected with SARS-CoV-2.
            </li>
            <li>
                People progress through several stages of infection: exposed
                (E), infectious asymptomatic (Ia), infectious symptomatic (Is),
                infectious hospitalised (Ih) and infectious ICU (Iu). Every
                E person becomes Ia but all other stages can be skipped.
            </li>
            <li>
                The level of infectiousness of people varies from stage to
                stage. People in the Is compartment are more infectiousness than
                people in Ia, Ih and Iu (the latter two because infectious
                control should be better in hospitals).
            </li>
            <li>
                At the end of the infection stages, a person either recovered
                (R) or dies (D).
            </li>
            <li>
                People can also become vaccinated (V), in which case, if they
                are uninfected they are more likely to remain so than
                susceptible people.
            </li>
            <li>
                But both recovered and vaccinated people can become susceptible
                again.
            </li>
            <li>
                At a random interval, a susceptible person becomes exposed to
                Covid outside the community. (This is so we can model
                introducing Covid continuously into the community.)
            </li>
        </ul>
        <p>
            In our model, our compartments are S, E, Ia, Is, Ih, Ii, R, V and D.
            The time step is one day. The probability at which people transition
            between two compartments is specified by the name of the source
            compartment, an underscore, _, and the name of the destination
            department. For example if we set Ia_Is to 0.2, this means there is
            a 20% chance that people in the infectious asymptomatic compartment
            will move to the infectious symptomatic compartment on a time step.
        </p>
        <p>
            People in some compartments can transition to one of two mutually
            exclusive compartments. For example there is also an Ia_R
            transition, representing people who move straight from asymptomatic
            infection to recovery. The model must first calculate the one
            transition and then the other. The order matters. The order in which
            the transitions are listed in the model is the order in which they
            are calculated.
        </p>
        <p>
            It's tricky to use $\underline{R_0}$ directly to calculate the
            number of people that become exposed per time step in this model.
            This is because the average number of days of infectiousness, $D$ in
            equation \eqref{eq:R0}, is very hard to calculate.
            <span class="review-query">Does this make sense?</span>
            Instead the parameter α replaces it so that on a given time step the
            number of new infections (i.e. the transition from S to E, S_E) is:

            \begin{equation} S\_E = { {α \times I \times S} \over N_0 }
            \end{equation}

            where $N_0$ is the initial population.
        </p>
        <p>
            The rate at which susceptible people are exposed outside the
            community on a time step is given by the parameter $r$.
        </p>
        <p>
            The relative infectiousness of each infectious stage Ia, Is, Ih and
            Ii is specified by Inf_Ia, Inf_Is, Inf_ih and Inf_Ii respectively.
        </p>
        <p>
            Here is our macro model using difference equations.
        </p>
        <div id="macroCovid" class="sir">
            <noscript>You need Javascript enabled to run this webpage's models.</noscript>
        </div>

        <p>Here is a micro model that attempts to match the macro model as much
            as possible.
        </p>

        <div id="microCovid" class="sir">
            <noscript>You need Javascript enabled to run this webpage's models.</noscript>
        </div>

        <p>
            Try experimenting with different parameter values. In particular, in
            the default setting, we have a very vaccination-averse population.
            See what happens to the infections and deaths if a much higher
            vaccination rate is used.
        </p>

        <p>
            There are many shortcomings of these two models. Here are a few:
        </p>

        <ul>
            <li>
                They do not account for the large variations (heterogeneity) we
                have been seeing in infectious periods.
            </li>
            <li>
                While we try to model viral mutations by moving a proportion of
                vaccinated and recovered people back into the susceptible
                compartment, the way this works in reality is much more complex
                and we are not sufficiently capturing these dynamics here.
            </li>
            <li>
                Once vaccinated or recovered, the likelihood of dying with Covid
                on subsequent infections is greatly reduced but this is not
                modelled at all here, resulting in a mortality rate that is too
                high, at least with the default parameter values.
            </li>
        </ul>

        <p>
            Frankly with the default settings, neither model's infection curve
            looks much like any I've seen, and this may very well be due to
            these shortcomings.
        </p>

        <p>
            Removing these shortcomings would be easier in a micro model than a
            macro one. The number of compartments would multiply rapidly and the
            complexity of the model would likely tax even highly competent
            programmers. Heterogeneity is often especially hard to model in macro
            models.
        </p>

        <h2>Graphical depictions of health interventions ##TODO</h2>

        <aside>
            <button type="button">Finding the source of epidemics</button>
            <div>
                <p>
                    A rather different type of model to the ones we've discussed
                    are maps that trace the source and spread of an epidemic.
                    John Snow famously did the first such map to trace the
                    outbreak of the 1854 cholera epidemic in London to a public
                    water pump on Broad Street in Soho.
                </p>
                <figure>
                    <img src="512px-Snow-cholera-map-1.webp"
                         alt="Map by John Snow showing household deaths">
                    <img src="broadblock_revised.webp" alt="Zoomed in portion of John Snow's corrected map">
                    <figcaption>
                        Top: John Snow's map.<br>
                        Bottom: Zoomed in part of the
                        map.<br> The original map was presented on 4 December
                        1854 to the London Epidemiological Society and then,
                        with corrections, published in his book On the Mode
                        of Communication of Cholera. Sources: <a href="https://en.wikipedia.org/wiki/1854_Broad_Street_cholera_outbreak#/media/File:Snow-cholera-map-1.jpg">Wikipedia</a> and <a href="https://www.ph.ucla.edu/epi/snow/mapsbroadstreet.html">UCLA Department of Epidemiology, Fielding School of Public Health</a>.
                        The maps are in the public domain.
                    </figcaption>
                </figure>
                <p>
                    Each bar represents a cholera death in a household. Note how
                    the deaths cluster around the Broad Street pump. At the time
                    it was believed that cholera was caused by particles in the
                    air caused by decomposition. Snow overturned this theory by
                    showing that the source of infection was in the water from
                    the public pump that households in the area used. The full
                    story is more complicated and fascinating and told
                    fantastically well
                    in <a href="https://en.wikipedia.org/wiki/The_Ghost_Map">The
                    Ghost Map</a> by Steven Johnson.
                </p>
                <p>
                    More recently, in July 2022, Michael Worobey and his
                    colleagues <a href="https://www.science.org/doi/10.1126/science.abp8715">showed</a> that
                    the likely origin of Covid in humans was the Huanan
                    Seafood Wholesale Market. They presented several strands
                    of evidence. One of the most convincing is this map
                    which also shows how early cases clustered near the
                    market:
                </p>
                <figure>
                    <img src="https://www.science.org/cms/10.1126/science.abp8715/asset/c25e543d-8e80-4406-8784-dd35b1cadb09/assets/images/large/science.abp8715-f1.jpg"
                         alt="Map showing cluster of SARS-CoV-2 cases near Huanan Seafood Wholesale Market">
                    <figcaption>
                        Worobey et al. explain under the heading "Spatial
                        patterns of COVID-19 cases in Wuhan in December 2019
                        and January–February 2020":
                        <blockquote>
                            "(A) Locations of the 155 cases that we
                            extracted from the <a href="https://www.who.int/publications/i/item/who-convened-global-study-of-origins-of-sars-cov-2-china-part."> WHO mission report</a>.
                            Inset: map of Wuhan with the December 2019 cases
                            indicated with gray dots (no cases are obscured
                            by the inset). In both the inset and the main
                            panel, the location of the Huanan market is
                            indicated with a red square. (B) Probability
                            density contours reconstructed by a <a href="https://en.wikipedia.org/wiki/Kernel_density_estimation">kernel
                            density estimate</a> using all 155 COVID-19
                            cases locations from December 2019. The highest
                            density 50% contour marked is the area for which
                            cases drawn from the probability distribution
                            are as likely to lie inside as outside. Also
                            shown are the highest density 25%, 10%, 5%, and
                            1% contours. Inset: expanded view and the
                            highest density 1% probability density contour.
                            (C) Probability density contours reconstructed
                            using the 120 COVID-19 cases locations from
                            December 2019 that were unlinked to the Huanan
                            market. (D) Locations of 737 COVID-19 cases from
                            Weibo data dating to January–February 2020. (E)
                            The same highest probability density contours
                            (50% through 1%) as shown in (B) and (C) for 737
                            COVID-19 case locations from Weibo data."
                        </blockquote>
                        Source: Worobey et al. 2022. <a href="https://www.science.org/doi/10.1126/science.abp8715">The Huanan Seafood
                            Wholesale Market in Wuhan was the early epicenter of
                            the COVID-19 pandemic</a>. Science Vol. 377, No. 6609. See also: Pekar et al. 2022. <a href="https://www.science.org/doi/10.1126/science.abp8337">The molecular epidemiology of multiple zoonotic origins of SARS-CoV-2</a>.
                        Science Vol. 377, No. 6609, and Jang and Wang, 2022.
                        <a href="https://www.science.org/doi/10.1126/science.add8384">Wildlife trade is likely the source of SARS-CoV-2</a>.
                        Science Vol. 377, No. 6609.
                    </figcaption>
                </figure>
                <p>
                    While at the time of writing there is still some
                    speculation that SARS-CoV-2, the cause of Covid-19, may
                    have leaked from a laboratory in Wuhan, there is no
                    compelling evidence that this is the case. Instead
                    supported by the above analysis and molecular analysis
                    of the early cases, Worobey et al.conclude: "The precise
                    events surrounding virus spillover will always be
                    clouded, but all of the circumstantial evidence so far
                    points to more than one zoonotic event occurring in
                    Huanan market in Wuhan, China, likely during
                    November–December 2019."
                </p>
                <p>
                    There is much dispute, mainly on social media and by
                    some departments in the US government, on the origins of
                    SARS-CoV-2. But in science, and perhaps in most things,
                    it makes sense to go with where the current evidence
                    points. While this maxim isn't always straightforward to
                    apply, here it appears to be. As things stand, the
                    origins of SARS-CoV-2 were likely between animals and
                    humans in a wet market, not in a laboratory.
                </p>
            </div>
        </aside>

        <h2>Simulating thousands of infectious diseases ##TODO</h2>

        <h2>Calibrating models to real-world data</h2>

        <p>
            Imagine there's an outbreak of a new infectious disease in a distant
            part of the world. Luckily scientists quickly develop a test for the
            infection. Then the disease lands in your city, where you are the
            head of public health. You organise for 1,000 people to be randomly
            tested daily. Using this, you have the daily infection rate in your
            city. Now you want to fit an SEIR model to your data.
        </p>

        <p>
            In the graph below the blue line is the daily number of infections
            &mdash; the observed values &mdash; in the sample of 1,000 people.
            The pink line is an SEIR model. Adjust the values the parameters
            &mdash; $\underline{R_0}$, average number of days in the exposure
            compartment and average number of days in the infectious compartment
            &mdash; until the model fits the observed data as closely as
            possible. (The observed values change every time this webpage is
            refreshed, so if they look especially terrible, simply refresh the
            page.)
        </p>
        <div id="calibration-graph">
            <canvas id="calibration-chart"></canvas>
            <div>
                <label for="calibration-graph-R0">
                    <underline>R<sub>0</sub></underline></label>
                <input type="range" min="1" max="10" value="4"
                       id="calibration-graph-R0">
                <span id="calibration-graph-R0-value">4</span>
            </div>
            <div>
                <label for="calibration-graph-days-exposed">Days exposed</label>
                <input type="range" min="1" max="10" value="2"
                       id="calibration-graph-days-exposed">
                <span id="calibration-graph-days-exposed-value">2</span>
            </div>
            <div>
                <label for="calibration-graph-days-infectious">Days infectious</label>
                <input type="range" min="1" max="15" value="5"
                       id="calibration-graph-days-infectious">
                <span id="calibration-graph-days-infectious-value">2</span>
            </div>
        </div>

        <p>
            What you've just done is calibrate a model. Of course the real world
            is never as neat and tidy as this. (1) Daily surveys like this can
            almost never be done. (2) Even if they could the sample size would
            not consistently be 1,000. (3) This is coded so that the observed
            values are always within 5% of the points along an SEIR model with
            integer values for the three parameters; good luck finding a
            real-world epidemic that's so accommodating.
        </p>

        <p>
            When building a model that tries to explain the nature of a real
            epidemic, especially if it tries to predict the future course of
            that epidemic, it will likely be important to calibrate the
            model against known data points.
        </p>

        <p>
            For example the <a href="https://thembisa.org/">Thembisa model</a> is
            calibrated to fit adult HIV prevalence, antiretroviral
            metabolite data and adult mortality up to particular years. The
            model then produces a bunch of inferred demographic outputs up
            to those particular years, and also projects into the
            future. It's a complex model and the calibration process is
            especially complicated and <a href="https://thembisa.org/content/downloadPage/Thembisa4_4report"> worth reading</a>.
        </p>

        <p>
            The topic of model calibration (which, for the most part, is another
            name for function optimization, function approximation or regression
            analysis) could do with much more exposition in modelling
            literature. This is a somewhat superficial introduction.
        </p>

        <p>
            The first thing needed to calibrate a model is a way to measure
            the error between the real world calibration points and the
            model's outputs. The mean squared error is often a good choice
            for such an error function.  Given $n$ known real-world data
            points $Y_0, Y_1 ... Y_n$ and model outputs $y_0, y_1 ... y_n$,
            the mean squared error, $E$ is:

            \begin{equation} {1 \over n} \sum_{1}^{n} {(Y_i - y_i)}^2
            \end{equation}
        </p>

        <p>
            This mean squared error is partially differentiable with respect
            to each output, which means it can be used easily with function
            minimization techniques such as gradient descent.
            <span class="review-query">Is this correct?</span>
            Formally, the goal of calibration then is to find a set of
            values for the model parameters, $p_1, p_2 ... p_m$, that
            minimises the error function.
        </p>

        <p>
            Calibration of complex models can involve thousands of model
            executions. Stochastic micro models will generally take much
            longer to calibrate than their equivalent deterministic macro
            ones. There are two reasons for this: they take longer to run
            and, because they are stochastic, the model has to be rerun
            multiple times with each set of parameter values, $p_1, p_2
            ... p_m$, and then $y_1, y_2 ... y_n$ will be the average output
            values across the runs.
        </p>

        <p>
            There are many error minimization techniques.
        </p>

        <aside>
            <button type="button">Micro model implementation details</button>
            <div>
                <h5>Matching the difference equation macro models</h5>
                <p>
                    I've tried to implement the micro models to match as closely
                    as possible the macro models that use difference equations.
                    The code makes certain compromises to do this. For example,
                    $\lambda_t$ is calculated using the number of infections at
                    the end of the previous time step, not the current number of
                    infections which may have changed as the infection event
                    iterates over agents. Other than for the purpose of trying
                    to match the models as closely as possible, I see no reason
                    to do this.
                </p>
                <p>
                    Moreover, while thinking in terms of compartments make
                    sense for macro models, for micro or agent based models,
                    it's more natural to think of agents having states,
                    rather than being in compartments. In a macro model if
                    you wish to include additional characteristics such as
                    sex and age group, you would need to replicate all the
                    compartments for each sex and age group. But in a micro
                    model, without compartments, an agent could have a sex,
                    age and state. A state may even be partial (e.g. an
                    agent transitioning from an asymptomatic to symptomatic
                    phase &mdash; with different levels of infectiousness or
                    different subsequent behaviours &mdash; may do so
                    gradually), or an agent may be in multiple states.  As
                    models increase in complexity, macro models become
                    extremely difficult to implement, while the increase in
                    programming complexity in micro models is much slower.</p>
                <p>
                    Nevertheless in the micro models here I continue to talk
                    of agents being in compartments rather than states,
                    simply to keep the nomenclature consistent with the
                    macro models.
                </p>
                <h5>What programming language to use for micro models?</h5>
                <p>
                    There is far more debate on the Internet about which are the
                    best programming languages than the topic deserves. In fact,
                    there are many good programming languages and all of them
                    are flawed. Write your first simulations in a programming
                    language you feel comfortable with. If it's a prototype it
                    doesn't matter if it's Python, R, Ruby, Basic or whatever
                    your favourite algebra for expressing algorithms is.
                </p>
                <p>
                    If you need your simulation to execute many thousands of
                    times and you are finding it too slow, changing to a
                    compiled language like C, C++, Go, Fortran, Rust, Java
                    or even a lisp-type language, may be necessary. But
                    often the cause of execution being too slow isn't the
                    language but an algorithm you might be using. Perhaps
                    consider optimising or improving an algorithm before
                    going to the effort of learning a new programming
                    language.
                </p>
                <p>For what it's worth I tend to implement my micro models
                    in Python when I'm just prototyping and then C or C++ if
                    I truly need a lot more speed. But the models on this
                    web page are implemented in Javascript, because that is
                    the main programming language that the most popular web
                    browsers support.
                </p>
            </div>
        </aside>



        <h2>An example micro model in C++</h2>

        <p>
            Modellers I've spoken to often yearn to make their micro, or
            agent-based, models much faster. They usually don't have a computer
            science background and only know a smattering of C or C++. If you
            are in this boat, below is a heavily commented non-trivial, but not
            too complicated ether, example model in C++ that can be extended
            quite easily. (In the Github repository it is model_example.cc.) <span class="review-query">Should I do an
            equivalent Python program so that modellers, more used to the latter, can then compare with the C++ code? And R too?</span>
        </p>
        <p>
            The model has these characteristics:
        </p>
        <ul>
            <li>
                An agent can be in one of the following states: susceptible,
                exposed, infectious, recovered, vaccinated or dead.
            </li>
            <li>
                Once an agent is dead it is not processed further. It cannot
                change states again (obviously).
            </li>
            <li>
                Agents that are susceptible can become exposed through a
                slightly complex algorithm. On any time step a susceptible
                Agent, $A$, comes into contact with $n$ other agents, where
                $n$ is drawn from a normal distribution. Then for any of
                these $n$ agents who are in the infectious stage, $A$
                becomes exposed if a random number less than some
                pre-specified number between 0 and 1 is drawn.
            </li>
            <li>
                The rate at which agents move between the other states is
                occurs stochastically according to the model's parameters.
            </li>
        </ul>

        <p>Here is the code:</p>

        <iframe id="cc-micro-model-example"
                title="C++ micro model example"
                width="100%"
                height="500px"
                src="model_example.html">
        </iframe>

        <h2>Acknowledgements</h2>

        <p>
            Thanks to Alex Welte and Stefan Scholz for advice. I have learnt
            much about the modelling done here through discussions with Leigh
            Johnson, Marcus Low and Eduard Grebe. Stefan Scholz has coauthored
            papers with me, advised me, introduce me to various modelling
            software tools and helped me to understand calibration better.<br>
            All errors are my responsibility.
        </p>

        <footer>
            <nav>
                <a href="https://github.com/nathangeffen/understandingepi">Source code</a>
                <a href="https://www.simhub.online">Simhub</a>
            </nav>
            <p>
                Written by <a href="https://www.simhub.online/nathan/">Nathan Geffen</a> (&copy; 2023, <a href="mailto:nathan@simhub.online">email</a>)<br>
                <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img
                                                                                           alt="Creative Commons License"
                                                                                           src="cc.webp"></a><br>This work is licensed under the <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.<br>
                All source code used on this page is open source. Most of it is available under the <a href="https://www.gnu.org/licenses/agpl-3.0.html">GNU Affero General Public License</a>. See the section <a href="#copyright-details">Using the resources on this webpage</a>.
            </p>
        </footer>

        <script src="utils.js?v=20230321"></script>
        <script src="rk.js?v=20230321"></script>
        <script src="epimacro.js?v=20230321"></script>
        <script src="epimicro.js?v=20230321"></script>
        <script src="epi-ui.js?v=20230321"></script>
        <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
        <script src="calibration.js?v=20230325"></script>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js">
        </script>
        <script src="models.js?v=20230321"></script>

    </body>

</html>
